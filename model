from tensorflow.keras import regularizers
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential 

from tensorflow.keras import regularizers

tf.random.set_seed(40) # make model re-produceable using the same weights 
model = Sequential([
    tf.keras.Input(shape =(85)),
    tf.keras.layers.BatchNormalization(),
    Dense(30, kernel_initializer= 'he_normal', activation= 'relu', name ='layer1'),
    tf.keras.layers.BatchNormalization(),
    Dense(10, kernel_initializer= 'he_normal', activation= 'relu', name = 'layer2'),
    tf.keras.layers.BatchNormalization(),
    Dense(1, activation= 'linear', name = 'layer3')
], name = 'my_model'
) 
) 
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),
    optimizer = tf.keras.optimizers.Adam(0.01), 
    metrics = [tf.keras.metrics.BinaryAccuracy()],
)

history = model.fit(
    X_train, Y_train,
    epochs = 55
)
  
